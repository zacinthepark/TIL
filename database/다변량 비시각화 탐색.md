## 다변량 비시각화 탐색

---

- 다변량 비시각화 개요
    - 두 개 이상으로 구성된 변수 간 관계를 수치 및 통계적 지표 기반으로 파악
- 범주형 다변량 비시각화
    - 교차표 기반의 범주형 변수 내 범주 별 조합의 연관 관계 파악 및 비교
- 연속형 다변량 비시각화
    - 상관계수 기반의 연속형 변수 간 관계의 밀접함을 수치로 도출 및 비교 파악

### 다변량 비시각화

- 두 개 이상의 변수로 구성된 데이터의 관계를 교차표 및 상관계수 등으로 파악하는 데이터 탐색 유형
- 주어진 변수 간의 관계를 수치 및 통계적 지표 기반으로 파악하는 것이 목적

### 다변량 비시각화 종류

<img width="755" alt="eda23" src="https://github.com/zacinthepark/TIL/assets/86648892/c5d3c3fb-7b9c-43a9-94ce-763c3da41fd8">

### 교차표 (Cross tabulation)

<img width="733" alt="cross_tabulation" src="https://github.com/zacinthepark/TIL/assets/86648892/7cf853d5-8658-467a-a470-d6088a6de874">

<img width="743" alt="cross_tabulation1" src="https://github.com/zacinthepark/TIL/assets/86648892/44a39ea8-f40b-4c0d-96c9-3f7ad7d6e4ce">

### 범주별 요약 통계량

<img width="746" alt="sum" src="https://github.com/zacinthepark/TIL/assets/86648892/5d0a2f8e-6e65-4ea2-976b-8fab5000cec2">

### 상관계수 (Corr.coefficient)

<img width="749" alt="coefficient" src="https://github.com/zacinthepark/TIL/assets/86648892/07fc5510-51db-4f80-8e6d-f1c517c84527">

<img width="756" alt="high_correlation" src="https://github.com/zacinthepark/TIL/assets/86648892/95e1a9ee-82d1-4996-b1e5-900a7b387f5c">

- -1에서 +1의 범위를 가짐
- +1은 완벽한 양의 선형 상관관계, -1은 음의 선형 상관관계, 0은 상관관계가 없음
- 다중공선성이란 독립변수 간의 강한 상관관계를 뜻함
    - 독립변수의 일부가 다른 독립변수의 조합으로 표현될 수 있는 경우
    - 완벽하게 다중공선성을 제거하는 것은 현실적으로 어려움
    - 따라서 상관계수가 기준치보다 높게 나오는 컬럼들 중 하나를 고르고 나머지는 삭제하는 방법을 통해 변수 선택에 적용할 수 있음
    - 혹은 도메인 지식을 바탕으로 적합 변수를 선택할 수도, 상관성이 높게 나오는 변수들을 합쳐서 PCA와 같은 주성분 분석으로 새로운 특징을 생성하거나, 정규화를 통해 변수의 간격을 조정하는 등 여러 해결방안을 고려해야함

### 실습

```python
import numpy as np
import pandas as pd
```

```python
# 데이터 로딩
data_url = 'http://lib.stat.cmu.edu/datasets/boston'
raw_df = pd.read_csv(data_url, sep=r'\s+', skiprows=22, header=None)
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]
housing = pd.merge(pd.DataFrame(data), pd.DataFrame(target), left_index=True, right_index=True, how='inner')
housing.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 
                  'PTRATIO', 'B', 'LSTAT', 'MEDV']

# 데이터 copy
housing_data = housing.copy()
```

#### 범주형 - 범주형 다변량 비시각화

##### 교차표 (Cross Tabulation)

- 범주형 - 범주형 변수 교차하여 파악함으로써 각 범주 조합 간의 구성을 도출
- 조합 간의 구성을 통해 범주형 변수 간 관련성을 확인

```python
# 활용 데이터 확인
housing_data.describe()
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.613524</td>
      <td>11.363636</td>
      <td>11.136779</td>
      <td>0.069170</td>
      <td>0.554695</td>
      <td>6.284634</td>
      <td>68.574901</td>
      <td>3.795043</td>
      <td>9.549407</td>
      <td>408.237154</td>
      <td>18.455534</td>
      <td>356.674032</td>
      <td>12.653063</td>
      <td>22.532806</td>
    </tr>
    <tr>
      <th>std</th>
      <td>8.601545</td>
      <td>23.322453</td>
      <td>6.860353</td>
      <td>0.253994</td>
      <td>0.115878</td>
      <td>0.702617</td>
      <td>28.148861</td>
      <td>2.105710</td>
      <td>8.707259</td>
      <td>168.537116</td>
      <td>2.164946</td>
      <td>91.294864</td>
      <td>7.141062</td>
      <td>9.197104</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.006320</td>
      <td>0.000000</td>
      <td>0.460000</td>
      <td>0.000000</td>
      <td>0.385000</td>
      <td>3.561000</td>
      <td>2.900000</td>
      <td>1.129600</td>
      <td>1.000000</td>
      <td>187.000000</td>
      <td>12.600000</td>
      <td>0.320000</td>
      <td>1.730000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.082045</td>
      <td>0.000000</td>
      <td>5.190000</td>
      <td>0.000000</td>
      <td>0.449000</td>
      <td>5.885500</td>
      <td>45.025000</td>
      <td>2.100175</td>
      <td>4.000000</td>
      <td>279.000000</td>
      <td>17.400000</td>
      <td>375.377500</td>
      <td>6.950000</td>
      <td>17.025000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.256510</td>
      <td>0.000000</td>
      <td>9.690000</td>
      <td>0.000000</td>
      <td>0.538000</td>
      <td>6.208500</td>
      <td>77.500000</td>
      <td>3.207450</td>
      <td>5.000000</td>
      <td>330.000000</td>
      <td>19.050000</td>
      <td>391.440000</td>
      <td>11.360000</td>
      <td>21.200000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.677083</td>
      <td>12.500000</td>
      <td>18.100000</td>
      <td>0.000000</td>
      <td>0.624000</td>
      <td>6.623500</td>
      <td>94.075000</td>
      <td>5.188425</td>
      <td>24.000000</td>
      <td>666.000000</td>
      <td>20.200000</td>
      <td>396.225000</td>
      <td>16.955000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>88.976200</td>
      <td>100.000000</td>
      <td>27.740000</td>
      <td>1.000000</td>
      <td>0.871000</td>
      <td>8.780000</td>
      <td>100.000000</td>
      <td>12.126500</td>
      <td>24.000000</td>
      <td>711.000000</td>
      <td>22.000000</td>
      <td>396.900000</td>
      <td>37.970000</td>
      <td>50.000000</td>
    </tr>
  </tbody>
</table>
</div>

```python
# 데이터 설명에 따라 CHAS 컬럼을 범주형 데이터로 변환
housing_data = housing_data.astype({'CHAS': 'object'})
```

```python
# 타겟변수인 주택가격 (MEDV) 범주화
# 평균 가격 기반으로 고가, 저가 범주로 구분
medv_bins = [0,
             np.mean(housing_data['MEDV']), 
             np.max(housing_data['MEDV'])]
medv_names = ['cheap', 'expensive']
housing_data['MEDV_G'] = pd.cut(housing_data['MEDV'], medv_bins, labels=medv_names)
housing_data
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
      <th>MEDV_G</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
      <td>expensive</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
      <td>cheap</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
      <td>expensive</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
      <td>expensive</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
      <td>expensive</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
      <td>cheap</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
      <td>cheap</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
      <td>expensive</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
      <td>cheap</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
      <td>cheap</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 15 columns</p>
</div>

```python
# 주택가격과 범주화된 독립변수 간 관계 확인
# 1) CHAS 변수와의 관계
rst_CHAS = pd.crosstab(housing_data['CHAS'], housing_data['MEDV_G'], margins=True)
rst_CHAS
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>MEDV_G</th>
      <th>cheap</th>
      <th>expensive</th>
      <th>All</th>
    </tr>
    <tr>
      <th>CHAS</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.0</th>
      <td>282</td>
      <td>189</td>
      <td>471</td>
    </tr>
    <tr>
      <th>1.0</th>
      <td>15</td>
      <td>20</td>
      <td>35</td>
    </tr>
    <tr>
      <th>All</th>
      <td>297</td>
      <td>209</td>
      <td>506</td>
    </tr>
  </tbody>
</table>
</div>

- 대부분의 타운이 강 경계에 위치하지 않음

```python
# 관측 범위를 평균을 기준으로 구간화
# INDUS 변수 범주화
# INDUS_LOW: 비소매 사업 지역 비율이 낮음 -> 소매 사업 지역 토지 비율이 많음
# INDUS_HIGH: 비소매 사업 지역 비율이 높음 -> 소매 사업 지역 토지 비율이 적음
indus_bins = [0,
             np.mean(housing_data['INDUS']), 
             np.max(housing_data['INDUS'])]
indus_names = ['INDUS_LOW', 'INDUS_HIGH']
housing_data['INDUS_G'] = pd.cut(housing_data['INDUS'], indus_bins, labels=indus_names)
housing_data
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
      <th>MEDV_G</th>
      <th>INDUS_G</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
      <td>expensive</td>
      <td>INDUS_LOW</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
      <td>cheap</td>
      <td>INDUS_LOW</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
      <td>expensive</td>
      <td>INDUS_LOW</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
      <td>expensive</td>
      <td>INDUS_LOW</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
      <td>expensive</td>
      <td>INDUS_LOW</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
      <td>cheap</td>
      <td>INDUS_HIGH</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
      <td>cheap</td>
      <td>INDUS_HIGH</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
      <td>expensive</td>
      <td>INDUS_HIGH</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
      <td>cheap</td>
      <td>INDUS_HIGH</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
      <td>cheap</td>
      <td>INDUS_HIGH</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 16 columns</p>
</div>

```python
# 주택가격과 범주화된 독립변수 간 관계 확인
# 2) INDUS_G 변수와의 관계
rst_INDUS = pd.crosstab(housing_data['INDUS_G'], housing_data['MEDV_G'], margins=True)

# 행별 범주 구성비율 확인
# crosstab에서 normalize='index'로 행별 비율 환산 가능
rst_INDUS['ratio_cheap'] = np.round((rst_INDUS['cheap']/rst_INDUS['All'])*100, 2)
rst_INDUS['ratio_expensive'] = np.round((rst_INDUS['expensive']/rst_INDUS['All'])*100, 2)

rst_INDUS
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>MEDV_G</th>
      <th>cheap</th>
      <th>expensive</th>
      <th>All</th>
      <th>ratio_cheap</th>
      <th>ratio_expensive</th>
    </tr>
    <tr>
      <th>INDUS_G</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>INDUS_LOW</th>
      <td>126</td>
      <td>168</td>
      <td>294</td>
      <td>42.86</td>
      <td>57.14</td>
    </tr>
    <tr>
      <th>INDUS_HIGH</th>
      <td>171</td>
      <td>41</td>
      <td>212</td>
      <td>80.66</td>
      <td>19.34</td>
    </tr>
    <tr>
      <th>All</th>
      <td>297</td>
      <td>209</td>
      <td>506</td>
      <td>58.70</td>
      <td>41.30</td>
    </tr>
  </tbody>
</table>
</div>

- 비소매 사업지역 비율이 평균 대비 높을수록 (INDUS_HIGH), 주택가격이 전체 평균 대비 낮은 지역이 많음
- 비소매 사업지역 비율이 평균 대비 낮은 경우 (INDUS_LOW), 비등한 관계를 보임

```python
# RAD 변수 범주화
# RAD_LOW: 고속도로 접근성 지수가 낮음
# RAD_HIGH: 고속도로 접근성 지수가 높음
rad_bins = [0,
             np.mean(housing_data['RAD']), 
             np.max(housing_data['RAD'])]
rad_names = ['RAD_LOW', 'RAD_HIGH']
housing_data['RAD_G'] = pd.cut(housing_data['RAD'], rad_bins, labels=rad_names)

# 3) RAD_G 변수와의 관계
rst_RAD = pd.crosstab(housing_data['RAD_G'], housing_data['MEDV_G'], margins=True)

# 행별 범주 구성비율 확인

rst_RAD['ratio_cheap'] = np.round((rst_RAD['cheap']/rst_RAD['All'])*100, 2)
rst_RAD['ratio_expensive'] = np.round((rst_RAD['expensive']/rst_RAD['All'])*100, 2)

rst_RAD
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>MEDV_G</th>
      <th>cheap</th>
      <th>expensive</th>
      <th>All</th>
      <th>ratio_cheap</th>
      <th>ratio_expensive</th>
    </tr>
    <tr>
      <th>RAD_G</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>RAD_LOW</th>
      <td>183</td>
      <td>191</td>
      <td>374</td>
      <td>48.93</td>
      <td>51.07</td>
    </tr>
    <tr>
      <th>RAD_HIGH</th>
      <td>114</td>
      <td>18</td>
      <td>132</td>
      <td>86.36</td>
      <td>13.64</td>
    </tr>
    <tr>
      <th>All</th>
      <td>297</td>
      <td>209</td>
      <td>506</td>
      <td>58.70</td>
      <td>41.30</td>
    </tr>
  </tbody>
</table>
</div>

- 방사형 고속도로까지 접근성 지수가 높은 경우(RAD_HIGH), 주택가격이 전체 평균 대비 낮은 지역이 많음
- 방사형 고속도로까지 접근성 지수가 평균 대비 낮은 경우에는(RAD_LOW) 비등한 관계를 보임

```python
# INDUS_G 및 RAD_G를 교차하여 MEDV_G 구성 확인
rst_df = pd.crosstab([housing_data['RAD_G'], housing_data['INDUS_G']], housing_data['MEDV_G'],
                     margins=True)

rst_df['ratio_cheap'] = np.round((rst_df['cheap']/rst_df['All'])*100, 2)
rst_df['ratio_expensive'] = np.round((rst_df['expensive']/rst_df['All'])*100, 2)

rst_df
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MEDV_G</th>
      <th>cheap</th>
      <th>expensive</th>
      <th>All</th>
      <th>ratio_cheap</th>
      <th>ratio_expensive</th>
    </tr>
    <tr>
      <th>RAD_G</th>
      <th>INDUS_G</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">RAD_LOW</th>
      <th>INDUS_LOW</th>
      <td>126</td>
      <td>168</td>
      <td>294</td>
      <td>42.86</td>
      <td>57.14</td>
    </tr>
    <tr>
      <th>INDUS_HIGH</th>
      <td>57</td>
      <td>23</td>
      <td>80</td>
      <td>71.25</td>
      <td>28.75</td>
    </tr>
    <tr>
      <th>RAD_HIGH</th>
      <th>INDUS_HIGH</th>
      <td>114</td>
      <td>18</td>
      <td>132</td>
      <td>86.36</td>
      <td>13.64</td>
    </tr>
    <tr>
      <th>All</th>
      <th></th>
      <td>297</td>
      <td>209</td>
      <td>506</td>
      <td>58.70</td>
      <td>41.30</td>
    </tr>
  </tbody>
</table>
</div>

- 기존 개별 변수 결과
    - INDUS_G와 RAD_G가 모두 전체 평균 대비 낮은 경우(LOW 레벨) 주택 가격 범주 구분이 두드러지지 않음
- 함께 교차하여 비교했을 시 개별 컬럼 별 비율 구성보다 조금 더 구분되어짐을 보임 (RAD_G='RAD_LOW' and INDUS_G='INDUS_HIGH')
    - 고속도로 접근성 지수는 낮으나, 상업지역이 적은 경우 비교적 주택 가격이 평균대비 낮은 편
- 다만, INDUS_G와 RAD_G 모두 LOW 레벨일 때 (전체 평균보다 낮은) 주택 가격 범주 구분이 두드러지지 않음
- 범주형으로 변환하여 분석으로 활용할 경우, 조금 더 세밀하게 범주 범위 조정 고려 필요

```python
# 관측 범위를 동일한 길이로 구간화
# 4) INDUS 변수 범위 재조정
re_indus_bins = [0,
             np.max(housing_data['INDUS'])/4*1, 
             np.max(housing_data['INDUS'])/4*2, 
             np.max(housing_data['INDUS'])/4*3, 
             np.max(housing_data['INDUS'])]
re_indus_names = ['INDUS_G1', 'INDUS_G2', 'INDUS_G3', 'INDUS_G4']
housing_data['RE_INDUS_G'] = pd.cut(housing_data['INDUS'], re_indus_bins, labels=re_indus_names)

# 5) RE_INDUS_G 변수와의 관계
rst_RE_INDUS = pd.crosstab(housing_data['RE_INDUS_G'], housing_data['MEDV_G'], margins=True)

# 행별 범주 구성비율 확인

rst_RE_INDUS['ratio_cheap'] = np.round((rst_RE_INDUS['cheap']/rst_RE_INDUS['All'])*100, 2)
rst_RE_INDUS['ratio_expensive'] = np.round((rst_RE_INDUS['expensive']/rst_RE_INDUS['All'])*100, 2)

rst_RE_INDUS
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>MEDV_G</th>
      <th>cheap</th>
      <th>expensive</th>
      <th>All</th>
      <th>ratio_cheap</th>
      <th>ratio_expensive</th>
    </tr>
    <tr>
      <th>RE_INDUS_G</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>INDUS_G1</th>
      <td>56</td>
      <td>139</td>
      <td>195</td>
      <td>28.72</td>
      <td>71.28</td>
    </tr>
    <tr>
      <th>INDUS_G2</th>
      <td>79</td>
      <td>31</td>
      <td>110</td>
      <td>71.82</td>
      <td>28.18</td>
    </tr>
    <tr>
      <th>INDUS_G3</th>
      <td>136</td>
      <td>38</td>
      <td>174</td>
      <td>78.16</td>
      <td>21.84</td>
    </tr>
    <tr>
      <th>INDUS_G4</th>
      <td>26</td>
      <td>1</td>
      <td>27</td>
      <td>96.30</td>
      <td>3.70</td>
    </tr>
    <tr>
      <th>All</th>
      <td>297</td>
      <td>209</td>
      <td>506</td>
      <td>58.70</td>
      <td>41.30</td>
    </tr>
  </tbody>
</table>
</div>

- 비소매 사업지역 비율을 재조정한 독립변수(RE_INDUS_G)와 주택가격 범주(MEDV_G) 변수와의 관계
- 각 범주별 주택가격의 높고 낮음이 비교적 전보다 차이 두드러짐
- 비소매 사업지역 비율 정도가 낮을수록 (상업지구가 많을수록) 주택가격이 높은 형상을 보임 (INDUS_G1 기준)

```python
# RE_INDUS_G 및 RAD_G를 교차하여 MEDV_G 구성 확인
rst_df = pd.crosstab([housing_data['RAD_G'], housing_data['RE_INDUS_G']], housing_data['MEDV_G'],
                     margins=True)

rst_df['ratio_cheap'] = np.round((rst_df['cheap']/rst_df['All'])*100, 2)
rst_df['ratio_expensive'] = np.round((rst_df['expensive']/rst_df['All'])*100, 2)

rst_df
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MEDV_G</th>
      <th>cheap</th>
      <th>expensive</th>
      <th>All</th>
      <th>ratio_cheap</th>
      <th>ratio_expensive</th>
    </tr>
    <tr>
      <th>RAD_G</th>
      <th>RE_INDUS_G</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">RAD_LOW</th>
      <th>INDUS_G1</th>
      <td>56</td>
      <td>139</td>
      <td>195</td>
      <td>28.72</td>
      <td>71.28</td>
    </tr>
    <tr>
      <th>INDUS_G2</th>
      <td>79</td>
      <td>31</td>
      <td>110</td>
      <td>71.82</td>
      <td>28.18</td>
    </tr>
    <tr>
      <th>INDUS_G3</th>
      <td>22</td>
      <td>20</td>
      <td>42</td>
      <td>52.38</td>
      <td>47.62</td>
    </tr>
    <tr>
      <th>INDUS_G4</th>
      <td>26</td>
      <td>1</td>
      <td>27</td>
      <td>96.30</td>
      <td>3.70</td>
    </tr>
    <tr>
      <th>RAD_HIGH</th>
      <th>INDUS_G3</th>
      <td>114</td>
      <td>18</td>
      <td>132</td>
      <td>86.36</td>
      <td>13.64</td>
    </tr>
    <tr>
      <th>All</th>
      <th></th>
      <td>297</td>
      <td>209</td>
      <td>506</td>
      <td>58.70</td>
      <td>41.30</td>
    </tr>
  </tbody>
</table>
</div>


- INDUS 변수 범주 범위를 재조정하여 새로 교차한 결과 변수별 2개 범주 구분 시 보다 (평균 대비), 주택가격 구분이 조금 더 명확
    - RAD_G='RAD_LOW' and RE_INDUS_G='INDUS_G3'의 경우 제외하고 구분이 조금 더 명확
- 고속도로 접근성이 낮고, 상업지구가 많을 경우 전체 주택가격의 평균보다 높은 지역이 더 많음
    - RAD_G='RAD_LOW' and INDUS_G='INDUS_G1'
- 이처럼 범주 범위 조정에 따라 (범주 병합 & 분해) 변수 간 관계 파악 관점을 다양하게 바라볼 수 있고 분석 활용에 고려 가능
- 기타 활용 방안
    - 범주형 변수 내 범주 간의 조합 관계를 규칙(Rule)으로 생성하여 파생변수 생성 및 분석 모델링 활용

#### 범주형 - 연속형 다변량 비시각화

##### 범주 별 요약 통계

- 범주형 - 연속형 변수 교차하여 파악함으로써 각 범주 조합 간의 대표 수치 도출
- 대표적 수치 도출을 통해 범주 간 차이 확인

```python
# 주택가격 범주 별 INDUS 변수 집계 (평균 활용)
pd.DataFrame(housing_data.groupby(['MEDV_G'])['INDUS'].mean())
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>INDUS</th>
    </tr>
    <tr>
      <th>MEDV_G</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cheap</th>
      <td>13.813266</td>
    </tr>
    <tr>
      <th>expensive</th>
      <td>7.333349</td>
    </tr>
  </tbody>
</table>
</div>

```python
# 주택가격 범주 별 INDUS 변수 집계 (중앙값 활용)
pd.DataFrame(housing_data.groupby(['MEDV_G'])['INDUS'].median())
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>INDUS</th>
    </tr>
    <tr>
      <th>MEDV_G</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cheap</th>
      <td>18.10</td>
    </tr>
    <tr>
      <th>expensive</th>
      <td>5.86</td>
    </tr>
  </tbody>
</table>
</div>

- 주택가격이 높은 지역은 Town 내 INDUS 값이 적은 (상업지구 비중이 더 많은) 경향을 보임
- 주택가격 범주 별 INDUS 변수의 집계량의 차이는 평균값보다, 중앙값이 더 두드러지게 보임

```python
# 주택가격 범주 별 AGE 변수 집계 (평균 활용)
# AGE: 1940년 이전에 건축된 주택이 차지하는 비율
pd.DataFrame(housing_data.groupby(['MEDV_G'])['AGE'].mean())
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AGE</th>
    </tr>
    <tr>
      <th>MEDV_G</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cheap</th>
      <td>79.009764</td>
    </tr>
    <tr>
      <th>expensive</th>
      <td>53.746411</td>
    </tr>
  </tbody>
</table>
</div>

```python
# 주택가격 범주 별 AGE 변수 집계 (평균 활용)
pd.DataFrame(housing_data.groupby(['MEDV_G'])['AGE'].median())
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AGE</th>
    </tr>
    <tr>
      <th>MEDV_G</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cheap</th>
      <td>88.6</td>
    </tr>
    <tr>
      <th>expensive</th>
      <td>52.6</td>
    </tr>
  </tbody>
</table>
</div>

- 주택가격이 높은 지역은 Town 내 오래된 주택 비율이 더 낮고 비교적 신식 건물이 많은 경향을 보임
- 주택가격 범주 별 AGE 변수의 집계량의 차이는 평균값보다, 중앙값이 더 두드러지게 보임
- 분석 목적 혹은 분석 환경에 따라 많은 데이터를 특정 기준으로 집계하여 분석 알고리즘에 적용해야 하는 경우가 존재
    - Case. 시계열 데이터를 기준 시점 별 집계하여 분석 알고리즘 적용
        - 공장 내 많은 기기 별 작동 및 환경 이력 데이터가 1일에 한번씩 적재되어짐
        - 월별,기기별로 데이터를 집계하여 고장 예측 분석 모델링에 활용
- 집계 기준(범주) 및 집계 방법(평균, 중앙값 등)에 따라 분석 모델링에 적용할 변수 생성이 달라짐
- 즉, 집계 기준 별 차이가 두드러지는 집계 방법에 대한 확인과 고려가 필요하며, 범주형-연속형 관계 테이블을 통해 확인 가능함

#### 연속형 - 연속형 다변량 비시각화

##### 상관관계

- 연속형 - 연속형 변수의 상관분석을 통해 관계성 정도를 파악
- 상관계수를 기반으로 연속형 변수 간의 밀접성 파악

- 상관계수 도출 방안
    - 한 컬럼과 다른 모든 컬럼들의 Correlation (corrwith)
    - 모든 컬럼 간의 Correlation (corr)
- 본 실습에서는 상관계수 중 많이 알려진 선형관계 강도와 방향을 조사하는 피어슨 상관계수를 활용 

```python
# 데이터 copy
housing_data = housing.copy()

# 데이터 설명에 따라 CHAS 컬럼을 범주형 데이터로 변환
housing_data = housing_data.astype({'CHAS': 'object'})
```


```python
# 주택가격과 독립변수 간의 상관관계 확인: Pearson 상관계수
np.round(housing_data.corrwith(housing_data['MEDV']), 2).sort_values()
```

<pre>
LSTAT     -0.74
PTRATIO   -0.51
INDUS     -0.48
TAX       -0.47
NOX       -0.43
CRIM      -0.39
AGE       -0.38
RAD       -0.38
CHAS       0.18
DIS        0.25
B          0.33
ZN         0.36
RM         0.70
MEDV       1.00
dtype: float64
</pre>

- RM: 주택 1가구당 평균 방의 개수
- LSTAT: 하위계층의 비율
- DIS: 5개의 보스턴 직업센터까지의 접근성 지수

- RM(0.70) 및 LSTAT(-0.74) 두 가지 컬럼이 주택가격과 연관성이 높음
- RM은 양의 상관관계를 지니고 있음: 방의 개수가 많을수록 주택가격이 높음
- LSTAT은 음의 상관관계를 지니고 있음: 하위 계층 비율이 높을 경우, 주택가격이 낮아짐

```python
# 모든 컬럼 간 상관관계 도출
np.round(housing_data.corr(), 2)
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>1.00</td>
      <td>-0.20</td>
      <td>0.41</td>
      <td>-0.06</td>
      <td>0.42</td>
      <td>-0.22</td>
      <td>0.35</td>
      <td>-0.38</td>
      <td>0.63</td>
      <td>0.58</td>
      <td>0.29</td>
      <td>-0.39</td>
      <td>0.46</td>
      <td>-0.39</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>-0.20</td>
      <td>1.00</td>
      <td>-0.53</td>
      <td>-0.04</td>
      <td>-0.52</td>
      <td>0.31</td>
      <td>-0.57</td>
      <td>0.66</td>
      <td>-0.31</td>
      <td>-0.31</td>
      <td>-0.39</td>
      <td>0.18</td>
      <td>-0.41</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.41</td>
      <td>-0.53</td>
      <td>1.00</td>
      <td>0.06</td>
      <td>0.76</td>
      <td>-0.39</td>
      <td>0.64</td>
      <td>-0.71</td>
      <td>0.60</td>
      <td>0.72</td>
      <td>0.38</td>
      <td>-0.36</td>
      <td>0.60</td>
      <td>-0.48</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>-0.06</td>
      <td>-0.04</td>
      <td>0.06</td>
      <td>1.00</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>0.09</td>
      <td>-0.10</td>
      <td>-0.01</td>
      <td>-0.04</td>
      <td>-0.12</td>
      <td>0.05</td>
      <td>-0.05</td>
      <td>0.18</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>0.42</td>
      <td>-0.52</td>
      <td>0.76</td>
      <td>0.09</td>
      <td>1.00</td>
      <td>-0.30</td>
      <td>0.73</td>
      <td>-0.77</td>
      <td>0.61</td>
      <td>0.67</td>
      <td>0.19</td>
      <td>-0.38</td>
      <td>0.59</td>
      <td>-0.43</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>-0.22</td>
      <td>0.31</td>
      <td>-0.39</td>
      <td>0.09</td>
      <td>-0.30</td>
      <td>1.00</td>
      <td>-0.24</td>
      <td>0.21</td>
      <td>-0.21</td>
      <td>-0.29</td>
      <td>-0.36</td>
      <td>0.13</td>
      <td>-0.61</td>
      <td>0.70</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.35</td>
      <td>-0.57</td>
      <td>0.64</td>
      <td>0.09</td>
      <td>0.73</td>
      <td>-0.24</td>
      <td>1.00</td>
      <td>-0.75</td>
      <td>0.46</td>
      <td>0.51</td>
      <td>0.26</td>
      <td>-0.27</td>
      <td>0.60</td>
      <td>-0.38</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-0.38</td>
      <td>0.66</td>
      <td>-0.71</td>
      <td>-0.10</td>
      <td>-0.77</td>
      <td>0.21</td>
      <td>-0.75</td>
      <td>1.00</td>
      <td>-0.49</td>
      <td>-0.53</td>
      <td>-0.23</td>
      <td>0.29</td>
      <td>-0.50</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.63</td>
      <td>-0.31</td>
      <td>0.60</td>
      <td>-0.01</td>
      <td>0.61</td>
      <td>-0.21</td>
      <td>0.46</td>
      <td>-0.49</td>
      <td>1.00</td>
      <td>0.91</td>
      <td>0.46</td>
      <td>-0.44</td>
      <td>0.49</td>
      <td>-0.38</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>0.58</td>
      <td>-0.31</td>
      <td>0.72</td>
      <td>-0.04</td>
      <td>0.67</td>
      <td>-0.29</td>
      <td>0.51</td>
      <td>-0.53</td>
      <td>0.91</td>
      <td>1.00</td>
      <td>0.46</td>
      <td>-0.44</td>
      <td>0.54</td>
      <td>-0.47</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>0.29</td>
      <td>-0.39</td>
      <td>0.38</td>
      <td>-0.12</td>
      <td>0.19</td>
      <td>-0.36</td>
      <td>0.26</td>
      <td>-0.23</td>
      <td>0.46</td>
      <td>0.46</td>
      <td>1.00</td>
      <td>-0.18</td>
      <td>0.37</td>
      <td>-0.51</td>
    </tr>
    <tr>
      <th>B</th>
      <td>-0.39</td>
      <td>0.18</td>
      <td>-0.36</td>
      <td>0.05</td>
      <td>-0.38</td>
      <td>0.13</td>
      <td>-0.27</td>
      <td>0.29</td>
      <td>-0.44</td>
      <td>-0.44</td>
      <td>-0.18</td>
      <td>1.00</td>
      <td>-0.37</td>
      <td>0.33</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>0.46</td>
      <td>-0.41</td>
      <td>0.60</td>
      <td>-0.05</td>
      <td>0.59</td>
      <td>-0.61</td>
      <td>0.60</td>
      <td>-0.50</td>
      <td>0.49</td>
      <td>0.54</td>
      <td>0.37</td>
      <td>-0.37</td>
      <td>1.00</td>
      <td>-0.74</td>
    </tr>
    <tr>
      <th>MEDV</th>
      <td>-0.39</td>
      <td>0.36</td>
      <td>-0.48</td>
      <td>0.18</td>
      <td>-0.43</td>
      <td>0.70</td>
      <td>-0.38</td>
      <td>0.25</td>
      <td>-0.38</td>
      <td>-0.47</td>
      <td>-0.51</td>
      <td>0.33</td>
      <td>-0.74</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>
</div>

강한 상관관계를 지닌 변수 조합 확인

- TAX-RAD (0.91): 재산세율이 높을수록, 방사형 고속도로까지 접근성 지수가 높음
- TAX-INDUS (0.72): 재산세율이 높을수록, 비상업지역의 비중이 높음 (상업지역 비중이 떨어짐)
- AGE-NOX (0.73): 1940년 이전 건축된 주택이 많은 지역일수록, 일산화질소 농도 높음
- AGE-DIS (-0.75): 1940년 이전 건축된 주택이 많은 지역일수록, 직업센터까지 접근성 지수가 떨어짐
- DIS-NOX (-0.77): 직업센터까지 접근성 지수가 떨어질수록, 일산화질소 농도 높음
- NOX-INDUS (0.76): 일산화질소 농도가 높을수록, 비상업지역의 비중이 높음 (상업지역 비중이 떨어짐)

```python
# 상관계수 유의성 검정
import scipy.stats as stats
stats.pearsonr(housing_data.TAX, housing_data.RAD)
```

<pre>
PearsonRResult(statistic=0.9102281885331875, pvalue=4.1299201193969435e-195)
</pre>

- TAX-RAD 관계는 매우 강한 상관관계를 보이며, 만일 Regression 분석 알고리즘을 활용할 경우 다중공선성 문제에 직면함
- 위 사항을 해결하기 위한 방안
    - 논리적으로 적합한 변수를 선택 혹은 종속변수와 관계성을 더 보이는 변수 선택(TAX-MEDV: -0.47, RAD-MEDV: -0.36)
    - 위 변수를 대상으로 PCA를 수행하는 등 새로운 특징을 생성하는 방안 고려 가능

- 위처럼 모든 상관관계를 파악하는 경우 컬럼이 많아질수록 파악이 어려움
    - 시각화의 필요성 존재!
