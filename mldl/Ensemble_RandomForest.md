### 앙상블(Ensemble)

- 부트스트랩은 복원 추출하는 것을 의미한다
- Random Forest는 Decision Tree 알고리즘을 기반으로 한 대표적인 배깅 알고리즘이다
- Random Forest에서 random한 것은 1: 랜덤하게 데이터를 샘플링, 2: 분할 기준이 되는 feature

- Gradient Boost
- 회귀 모델은 앞에서 찾지 못한 오차에 대해서, 다시 해당 오차에 대해 예측
    - 오차가 발생했다면, 그 오차값을 내가 예상해서 채워주겠다는 로직
    - max_depth만큼 지속적으로 오차를 채워주기
- 분류 모델은 앞에서 찾지 못한 것에 대해 가중치를 주는 것

![image](https://github.com/zacinthepark/TIL/assets/86648892/402bcb2d-564f-43da-a4ea-ea68d21de408)

- XGBoost는 결측치를 고려해서 학습을 함
    - 설문조사 미응답의 경우 해당 결측치는 의미있는 데이터가 될 수 있음

- sklearn Imputer: 결측치 처리용 패키지
- 비용함수: 비용함수(손실함수)는 모델의 예측값과 실제값 사이의 차이를 수치화해주는 함수입니다. 해당 함수의 함수 값이 낮을수록 모델의 예측이 실제와 가깝다는 것을 의미
- sklearn에 있는 모델들은 대부분 default 비용함수를 가지고 있으나, 특수한 경우 직접 설정할 수 있음
- 패널티를 부과한다는 것은 모델이 잘못된 추론을 했을경우 더 큰 비용을 부과하는것을 의미
- 소수 클래스를 잘못 추론했을 경우 더 큰 패널티를 주면 모델에 해당 오류에 큰 영향을 받게 하여 중요도를 높일 수 있음