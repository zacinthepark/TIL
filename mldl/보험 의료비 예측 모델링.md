## 보험 의료비 예측 모델링

---

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format = 'retina'
```

```python
path = 'https://raw.githubusercontent.com/jangrae/csv/master/insurance.csv'
data = pd.read_csv(path)
```

```python
data.head()
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>bmi</th>
      <th>children</th>
      <th>smoker</th>
      <th>region</th>
      <th>charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19</td>
      <td>female</td>
      <td>27.900</td>
      <td>0</td>
      <td>yes</td>
      <td>southwest</td>
      <td>16884.92400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18</td>
      <td>male</td>
      <td>33.770</td>
      <td>1</td>
      <td>no</td>
      <td>southeast</td>
      <td>1725.55230</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>male</td>
      <td>33.000</td>
      <td>3</td>
      <td>no</td>
      <td>southeast</td>
      <td>4449.46200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>33</td>
      <td>male</td>
      <td>22.705</td>
      <td>0</td>
      <td>no</td>
      <td>northwest</td>
      <td>21984.47061</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>male</td>
      <td>28.880</td>
      <td>0</td>
      <td>no</td>
      <td>northwest</td>
      <td>3866.85520</td>
    </tr>
  </tbody>
</table>
</div>

- age: 나이
- sex: 성별(female, male)
- bmi: 체질량지수(체중을 키의 제곱으로 나눈 값, 적정수준:18.5 - 24.9)
- children: 자녀 수
- smoker: 흡연 여부
- region: 거주지역(northeast, southeast, southwest, northwest)
- charges: 건강보험에서 지불한 의료비 - Target

```python
data.describe()
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>bmi</th>
      <th>children</th>
      <th>charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1338.000000</td>
      <td>1338.000000</td>
      <td>1338.000000</td>
      <td>1338.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>39.207025</td>
      <td>30.663397</td>
      <td>1.094918</td>
      <td>13270.422265</td>
    </tr>
    <tr>
      <th>std</th>
      <td>14.049960</td>
      <td>6.098187</td>
      <td>1.205493</td>
      <td>12110.011237</td>
    </tr>
    <tr>
      <th>min</th>
      <td>18.000000</td>
      <td>15.960000</td>
      <td>0.000000</td>
      <td>1121.873900</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>27.000000</td>
      <td>26.296250</td>
      <td>0.000000</td>
      <td>4740.287150</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>39.000000</td>
      <td>30.400000</td>
      <td>1.000000</td>
      <td>9382.033000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>51.000000</td>
      <td>34.693750</td>
      <td>2.000000</td>
      <td>16639.912515</td>
    </tr>
    <tr>
      <th>max</th>
      <td>64.000000</td>
      <td>53.130000</td>
      <td>5.000000</td>
      <td>63770.428010</td>
    </tr>
  </tbody>
</table>
</div>

```python
# 상관관계 시각화
sns.heatmap(data.corr(numeric_only=True),
            annot=True,
            cmap='Blues',
            cbar=False,
            square=True)
plt.show()
```

![z_insurance_1](https://github.com/zacinthepark/TIL/assets/86648892/9992d54b-1e3d-4795-949b-6cc3a32c963f)

```python
# Target 분포 확인
plt.figure(figsize=(8, 4))
plt.subplot(2, 1, 1)
plt.hist(data['charges'], bins=30, alpha=0.7, ec='k')
plt.subplot(2, 1, 2)
plt.boxplot(x=data['charges'], vert=False)
plt.show()
```

![z_insurance_2](https://github.com/zacinthepark/TIL/assets/86648892/e793a86b-570e-4ac3-beba-0ca3d0e6c156)

```python
# 흡연자 비율
plt.figure(figsize=(8, 3))
sns.countplot(x=data['smoker'])
plt.show()
```

![z_insurance_3](https://github.com/zacinthepark/TIL/assets/86648892/01afebab-1837-4768-80c8-1fd46ddbad53)

```python
# 남녀 비율
plt.figure(figsize=(8, 3))
sns.countplot(x=data['sex'])
plt.show()
```

![z_insurance_4](https://github.com/zacinthepark/TIL/assets/86648892/f0bd697c-3d35-4426-a298-2f31f4fe0219)

```python
# 흡연 여부에 따른 의료비
plt.figure(figsize=(8, 3))
sns.histplot(x=data['charges'], hue=data['smoker'], bins=40)
plt.show()
```

![z_insurance_5](https://github.com/zacinthepark/TIL/assets/86648892/88e9eb9d-6d9b-4ea1-b9f3-c010df9e10cf)

```python
target = 'charges'

x = data.drop(target, axis=1)
y = data.loc[:, target]
```

```python
# 가변수화 대상: sex, smoker, region
dumm_cols = ['sex', 'smoker', 'region']
x = pd.get_dummies(x, columns=dumm_cols, drop_first=True, dtype=int)
x.head()
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>bmi</th>
      <th>children</th>
      <th>sex_male</th>
      <th>smoker_yes</th>
      <th>region_northwest</th>
      <th>region_southeast</th>
      <th>region_southwest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19</td>
      <td>27.900</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18</td>
      <td>33.770</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>33.000</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>33</td>
      <td>22.705</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>28.880</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

# 정규화
scaler = MinMaxScaler()
scaler.fit(x_train)
x_train_s = scaler.transform(x_train)
x_test_s = scaler.transform(x_test)
```

```python
# xgboost 설치
# !pip install xgboost
```

```python
# lightgbm 설치
# !pip install lightgbm
```

```python
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor

from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
```

**Linear Regression**

```python
model_lr = LinearRegression()
cv_score = cross_val_score(model_lr, x_train, y_train, cv=5)
print('평균: ', cv_score.mean())
```

<pre>
평균:  0.7450313111847257
</pre>

```python
result = {}
result['Linear Regression'] = cv_score.mean()
```

**KNN**

```python
model_knn = KNeighborsRegressor()
cv_score = cross_val_score(model_knn, x_train_s, y_train, cv=5)
print('평균: ', cv_score.mean())
```

<pre>
평균:  0.7299441631128959
</pre>

```python
# 결과수집
result['KNN'] = cv_score.mean()
```

**Decision Tree**

```python
model_dt = DecisionTreeRegressor(random_state=1)
cv_score = cross_val_score(model_dt, x_train, y_train, cv=5)
print('평균: ', cv_score.mean())
```

<pre>
평균:  0.6953363994799545
</pre>

```python
# 결과수집
result['Decision Tree'] = cv_score.mean()
```

**Random Forest**

```python
model_rf = RandomForestRegressor(max_depth=5, random_state=1)
cv_score = cross_val_score(model_rf, x_train, y_train, cv=5)
print('평균: ', cv_score.mean())
```

<pre>
평균:  0.8498969846794002
</pre>

```python
# 결과수집
result['Random Forest'] = cv_score.mean()
```

**XGBoost**

```python
model_xgb = XGBRegressor(max_depth=5, random_state=1)
cv_score = cross_val_score(model_xgb, x_train, y_train, cv=5)
print('평균: ', cv_score.mean())
```

<pre>
평균:  0.802412985317825
</pre>

```python
# 결과수집
result['XGBoost'] = cv_score.mean()
```

**LightGBM**

```python
model_lgbm = LGBMRegressor(max_depth=5, importance_type='gain', random_state=1, verbose=-1)
cv_score = cross_val_score(model_lgbm, x_train, y_train, cv=5)
print('평균: ', cv_score.mean())
```

<pre>
평균:  0.8413364103626888
</pre>

```python
# 결과수집
result['LightGBM'] = cv_score.mean()
```

```python
# 성능 비교
print('=' * 40)
for m_name, score in result.items():
    print('*', m_name, score.round(3))
print('=' * 40)
```

<pre>
========================================
* Linear Regression 0.745
* KNN 0.73
* Decision Tree 0.695
* Random Forest 0.85
* XGBoost 0.802
* LightGBM 0.841
========================================
</pre>

```python
# 성능 시각화 비교
plt.barh(list(result.keys()), result.values())
plt.show()
```

![z_insurance_6](https://github.com/zacinthepark/TIL/assets/86648892/c028ac4e-520c-48ec-a237-3fba8ef15d89)

### 성능 튜닝

```python
model = RandomForestRegressor(random_state=1)
param = {'max_depth': range(1, 21)}

model = GridSearchCV(model,
                     param,
                     cv=5,
                     scoring='r2')

model.fit(x_train, y_train)
```

```python
# 최적 파라미터, 예측 최고 성능
print('최적파라미터:', model.best_params_)
print('최고성능:', model.best_score_)
```

<pre>
최적파라미터: {'max_depth': 4}
최고성능: 0.8519332169168268
</pre>

```python
# 변수 중요도 시각화
df = pd.DataFrame()
df['feature'] = list(x)
df['importance'] = model.best_estimator_.feature_importances_
df.sort_values(by='importance', ascending=True, inplace=True)

plt.figure(figsize=(5, 5))
plt.barh(y=df['feature'], width=df['importance'])
plt.show()
```

![z_insurance_7](https://github.com/zacinthepark/TIL/assets/86648892/40dc8555-d244-4262-adcc-862deb8922c0)

```python
# 성능 평가
y_pred = model.predict(x_test)
print('MSE: ', mean_squared_error(y_test, y_pred))
print('R2: ', r2_score(y_test, y_pred))
```

<pre>
MSE:  20400360.530432574
R2:  0.8560482679256518
</pre>
