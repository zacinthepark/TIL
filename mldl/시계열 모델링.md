## 시계열 모델링

---

### Sequential Data

- Sequential Data: 데이터의 분석단위끼리 순서가 있다
- Time Series: Sequential Data + 시간의 등간격

### 시계열 데이터 분석

- 통계적 시계열 모델링
    - $y$ 의 흐름 분석
    - ARIMA
- ML 기반 시계열 모델링
    - Feature Engineering을 통해 시간의 흐름을 $x$ 변수로 도출
- DL 기반 시계열 모델링
    - 시간흐름 구간(timesteps) 데이터들(2차원)이 분석 단위이므로 데이터셋은 3차원
    - RNN Layer

### 시계열 모델링 절차

- 잔차에는 아무런 패턴이 없었으면 좋겠어
    - 화이트 노이즈

#### 잔차 분석

- 실제 = 모델 + 오차

### 시계열 RNN

> 1. timesteps를 바탕으로 3차원 데이터셋 구성 (sliding window)
> 1-1. timesteps를 지정할 떄 유의미한 분석 단위가 무엇일지 생각해보고 지정
> 2. input_shape 지정

- 이전 timestamp의 값이 다음 timestamp의 값에 영향을 미침
- 오래된 값일수록 영향이 줄어듬
- 2차원 데이터가 input으로 들어가면 노드 하나에서 나오는 값은 스칼라 값

- 최근 4일간 데이터($x{0}$, $x{1}$, $x{2}$, $x{3}$)를 기반으로 다음날 주가 예측(${y}$)을 할 때
    - 최근 4일간 데이터: input data (4x4)
        - n: timsteps, 4
        - m: nfeatures, 4
    - $h{0}$: $x{0}$ 을 바탕으로 ${y}$ 예측
        - $x{0}$ input vector(4x1) 바탕으로 예측
    - $h{1}$: $h{0}$ + $x{1}$ 바탕으로 ${y}$ 예측
        - $x{1}$ input vector(4x1) + $h{0}$ hidden layer vector(4x1) 바탕으로 예측
    - $h{2}$: $h{1}$ + $x{2}$ 바탕으로 ${y}$ 예측
        - $x{2}$ input vector(4x1) + $h{1}$ hidden layer vector(4x1) 바탕으로 예측
    - $h{3}$: $h{2}$ + $x{3}$ 바탕으로 ${y}$ 예측
        - $x{3}$ input vector(4x1) + $h{2}$ hidden layer vector(4x1) 바탕으로 예측

![rnn_return_sequences](https://github.com/zacinthepark/TIL/assets/86648892/f7512cfc-5a53-4a31-95a0-e58635032cff)

- `return_sequences=False` 출력 크기: `1 * node수`
- `return_sequences=True` 출력 크기: `timesteps * node수`

- `SimpleRNN`에서 `(4, 4)` 데이터가 분석단위라면, `SimpleRNN(1)`을 거칠 시 `(4, 1)` 형태 데이터가 결과
- `SimpleRNN`의 `return_sequences` 옵션은 default가 `False`
    - $h{3}$ 만 넘김
- RNN Layer는 Sequential Data를 input으로 받아야함
- ($h{0}$, $h{1}$, $h{2}$, $h{3}$)는 Sequential Data, $h{3}$ 단독은 Sequential Data가 아님

### 시계열 LSTM

- timestep 간에 두 종류(Cell State, Hidden State)의 상태값 업데이트 관리
- RNN은 timesteps가 길면, 초창기 기억이 사라지게 되어있음
- Cell State: 장기 기억을 오래 유지하기 위한 메모리
- 오차를 줄이는 방향으로 가중치를 업데이트 (Forget Gate, Input Gate)
