## 성능 관리: 성능 관리: 과적합 방지하기, 모델 저장하기

---

![image](https://github.com/zacinthepark/TIL/assets/86648892/8cf2c211-c350-4f7e-955e-d8da493d99a2)

- 각각의 점들은 검증 성능을 계산한 것
- 그림에서 Variance는 랜덤하게 돌린 검증들 간 성능 편차
- 그림에서 Bias는 검증 성능이 얼마나 목표에 근접한지

### 딥러닝 모델 성능 높이기

#### 데이터

- 입력 데이터 정제, 적절한 전처리
- 데이터 늘리기
    - 열: 적절한 Feature 추가 &rarr; 성능 향상 (Bias 줄이기)
    - 행: 데이터 건수 늘리기 &rarr; 성능 편차 줄이기 (Variance 줄이기)

#### 모델 구조

- Hidden Layer, Node 수 탐색 및 늘리기 (권장)
    - elbow method: 성능 탐색에 있어 팔꿈치처럼 꺾이는 근방을 탐색해라
- 반복문
    - `keras-tuner`

#### 학습

- `epochs`: 10 ~ 50 사이에서 시작
    - Model Check Point, Early Stopping 으로 최적 모델 저장 가능
- `learning_rate`: 0.1 ~ 0.001 사이에서 시작

#### 과적합 문제

- 과적합 방지는 검증 성능 최적화와 일맥상통한다
- 모델링의 목적: 모집단 전체에서 두루 잘 맞추는 **적당한** 모델 만들기
- 과적합: **학습 데이터** 에서만 높은 성능, 다른 데이터에서는 낮은 성능

- 과적합 문제 해결
    - 데이터 건수 늘리기
    - 모델 복잡도 조절하기
        - 반복 학습 횟수(epochs) 적절히 : Early Stopping
        - 너무 많은 가중치 줄이기 : 가중치 규제(Regularization)

#### 모델 저장하기

- 최종 모델 저장: `model.save()`
- 체크포인트에서 모델 저장: `ModelCheckpoint()`
    - 성능이 개선되면 저장하기 가능

> Hidden Layer 수, Node 수, learning_rate, epoch 수, 과적합 방지

- 수동으로 최적의 Hidden Layer, Node 수 탐색 (권장)
    - elbow method: 성능 탐색에 있어 팔꿈치처럼 꺾이는 근방을 탐색해라
- keras-tuner를 이용하여 최적의 Node 수 탐색 가능
- epoch 수는 early stopping을 하거나, mcp를 통해 해결
- 과적합 방지를 위해 가중치 규제를 진행할 수도 있음

### Early Stopping

- `monitor='val_loss'`는 관심사가 validation error라는 것
- `min_delta` 값은 현재 모니터링 중인 오차의 최소값에서 이 값보다 커야 줄어야 인정해주는지 지정
- `patience`는 오차의 최소값에서 `min_delta`보다 줄어들지 않는 것을 몇 번 기다려줄 것인지 지정하는 것이며, 한 번 줄어들면 patience의 카운트는 초기화됨

### 가중치 규제

- 파라미터의 수가 많아질수록 딥러닝 모델의 복잡도는 올라간다
- 파라미터에 규제를 가하여 줄여보겠다는 것이 가중치 규제
- 이처럼 파라미터에 규제를 가하여 과적합을 방지하고 모델의 복잡도를 낮추려는 시도
- 간단히 말해 파라미터를 정리하는 것
- 강도(람다값)가 높을수록 일반화된(단순한) 모델이 됨
- 일반적으로 한 Layer에서 L1이나 L2 규제를 사용했다면, 다른 Layer에서도 동일한 규제 방법 사용
- 모든 층에 규제를 할 수도 있고, 노드가 많은 층게 규제를 할 수도 있고, 여러 실험을 통해 성능 최적화를 진행

### L1 규제: Lasso

### L2 규제: Ridge

### Dropout

- 과적합을 줄이기 위해 규제 기법 중 하나
