## 머신러닝(Machine Learning)의 개념

---

### 머신러닝이란?

> 데이터 -> 머신러닝 모델 (학습) -> 예측

- 머신러닝이란 명시적인 프로그래밍 없이 데이터를 이용해서 예측을 수행하는 알고리즘을 구현하는 기법을 뜻함
- 즉, 데이터로부터 컴퓨터가 어떤 패턴을 학습하는 알고리즘이라고 생각할 수 있음
- 머신러닝은 한국말로 기계학습이라고도 부름
    - 데이터에 기반한 학습

### 머신러닝이 필요한 이유

- 머신러닝 방법론을 이용할 경우, 인간이 정확히 하나하나 로직을 지정해주기 어려운 복잡한 문제를 데이터에 기반한 학습을 통해 해결할 수 있음
- e.g. 어떤 사용자에게 무슨 광고를 보여주는 것이 최적의 광고 배분 전략일까?
- 어떤 카드사용내역이 사기에 의한 사용내역이고 어떤 사용내역이 정상 사용내역일까?

### 예측 모델(Prediction Model)의 필요성

- 데이터 분석을 통한 정교한 예측 모델(Prediction Model)을 갖고 있을 경우, 중요한 비즈니스적 의사결정을 안정적이고 계획적으로 수행할 수 있음
- 1) 다음 달에 휴대폰 판매량은 얼마나 될까? : 생산 계획 및 재고관리 전략을 수립할 수 있음
- 2) 광고비를 100만원 더 집행하면 얼마나 많은 유저를 추가적으로 획득할 수 있을까? : 목표로 하는 유저 획득 수에 따른 광고비 집행 전략을 세울 수 있음

### 분류 문제(Classification) vs 회귀 문제(Regression)

- 이때 예측 모델 값의 형태에 따라서 분류 문제 혹은 회귀 문제로 나뉨
- **분류 문제(Classification)** : 예측하는 결과값이 이산값(Discrete Value)인 문제
    - 이 이미지에 해당하는 숫자는 1인가 2인가?
    - MNIST 숫자 분류 문제
    - 이미지 가운데 숫자가 있으면, 가운데 있는 숫자가 0~9 중 무엇인가 예측
    - 10개의 후보군 중 1개의 카테고리를 선택하는 것
    - 이미지에 대해서 강아지, 고양이, 호랑이 중 하나를 선택하는 것
- **회귀 문제(Regression)** : 예측하는 결과값이 연속값(Continuous Value)인 문제
    - 3개월 뒤 이 아파트 가격은 2억1천만원일 것인가? 2억2천만원일 것인가?
    - 숫자를 예측하는 것

### 머신러닝 알고리즘의 3가지 분류: Supervised Learning, Unsupervised Learning, Reinforcement Learning

- **Supervised Learning (지도학습)** : 인풋 데이터와 그에 대한 정답 쌍 (x,y)를 이용해서 학습하는 방법론

- **Unsupervised Learning (비지도학습)** : 인풋 데이터 (x)만을 이용해서 데이터의 숨겨진 특징을 학습하는 방법론

- **Reinforcement Learning (강화학습)** : Reward를 제공하는 Environment와 Environment 내에서 행동을 수행하는 Agent의 상호작용을 통해 학습하는 방법론

### 지도학습(Supervised Learning)

![image](https://github.com/zacinthepark/TIL/assets/86648892/009b8ac7-206c-4d12-b4b5-75aad00ea9eb)

- 지도학습은 정답 데이터가 존재하는 상황에서 학습하는 알고리즘입니다. 좀 더 엄밀하게 정의하면 **입력 데이터 x와 그에 대한 정답 레이블(label) y의 쌍(pair) (x,y)** 를 이용해서 학습하는 알고리즘입니다.
- 예를 들어, 그림과 같은 28 x 28 크기의 이미지인 MNIST 데이터셋이 있으면 이를 이용해 학습을 진행할 때, 지도 학습의 트레이닝 데이터셋(Traning Dataset)은 다음과 같이 구성될 것입니다.
- (0을 나타내는 28 x 28 이미지, 0), (7을 나타내는 28 x 28 이미지, 7), (6을 나타내는 28 x 28 이미지, 6), (0을 나타내는 28 x 28 이미지, 0), ...
- 학습과정에서 해당 데이터에 대한 정답을 머신러닝 알고리즘에게 보여주면서 학습을 하는 방식

- 분류 문제: **예측** 하는 결과값이 이산값인 문제
    - 위의 문제는 분류 문제에 해당
- 회귀문제: **예측** 하는 결과값이 연속값인 문제

- 현재 대부분의 딥러닝 알고리즘이 사용하는 방법론
- 딥러닝에서 지도학습으로 방법론으로 주요 사용되는 구조는 CNN(Convolutional Neural Networks), RNN(Recurrent Neural Networks)입니다.

### 비지도학습(Unsupervised Learning)

![clustering](https://github.com/zacinthepark/TIL/assets/86648892/f9fab31d-411d-4055-af2a-aa2306a3a6b6)

- 비지도학습은 정답 레이블 y 없이 입력 데이터 x만을 이용해서 학습하는 알고리즘입니다. 즉, 입력 데이터 (x)의 형태로 학습을 진행합니다.
- 비지도학습은 지도학습과 목적이 조금 다릅니다. 지도학습의 목적이 **어떤 값에 대한 예측을 수행** 하는 것이라면 비지도학습은 **데이터의 숨겨진 특징(Hidden Feature)을 찾아내는 것** 에 목적이 있습니다.
- 예를 들어, 그림의 왼쪽 그림처럼 데이터가 무작위로 분포되어 있을 때, 비지도학습의 일종인 **클러스터링(Clustering) 알고리즘**을 이용하면 오른쪽 그림과 같이 비슷한 데이터들끼리 3개의 그룹으로 묶을 수 있습니다.
- 대량의 뉴스 기사를 가지고 있는 상태에서 '뉴스'라는 데이터를 가지고 있지만, 클러스터링 알고리즘을 적용하면 경제 뉴스, 스포츠 뉴스, 기술 관련 뉴스 등으로 뉴스라고 총칭되던 데이터의 숨겨져 있던 카테고리를 알아낼 수 있음

- 비지도학습은 단독으로 사용하기보다는 비지도학습으로 파악한 데이터의 숨겨진 특징을 원본 데이터 대신 지도학습의 인풋 데이터로 활용해서 지도학습의 성능을 더욱 끌어올리는 용도로 많이 활용됩니다.
- 대표적인 비지도학습의 방법론으로는 **주성분 분석(Principal Component Analysis(PCA))** 이 있고, 딥러닝에서 비지도학습을 위해 많이 사용되는 구조는 **오토인코더(Autoencoder)** 입니다.

### 강화학습(Reinforcement Learning)

![rl](https://github.com/zacinthepark/TIL/assets/86648892/95f91d40-894f-40b0-b254-526dad096900)

- 강화학습은 앞서 살펴본 지도학습과 비지도학습과는 학습하는 방법이 조금 다른 기법입니다.
- 앞서 살펴본 알고리즘들은 데이터가 이미 주어진 **정적인 상태(Static Environment)** 에서 학습을 진행했다면, 강화학습은 **에이전트(Agent)** 가 주어진 **환경(State)** 에서 어떤 **행동(Action)** 을 취하고 이에 대한 **보상(Reward)** 을 얻으면서 학습을 진행합니다.
    - 시뮬레이션 환경에서 에이전트가 특정 행동을 하면, 그 행동에 대한 결과를 보상이라는 것으로 에이전트에게 알려주고, 보상을 기반으로 학습을 진행하고, 현재 state가 다음 state로 넘어감
- 알파고 프로그램이 대표적인 강화학습 예시
    - 바둑을 플레이하는 에이전트 바둑을 플레이하는 액션을 취하고, 바둑을 이기면 +1, 비기면 0, 지면 -1 reward를 주는 식으로 학습

- 이때 에이전트는 **보상을 최대화(Maximize)** 하도록 학습을 진행합니다.
- 즉, 강화학습은 동적인 상태(Dynamic Environment)에서 데이터를 수집하는 과정까지 학습 과정에 포함되어 있는 알고리즘입니다.
- 강화학습의 대표적인 알고리즘으로는 Q-Learning이 있고, 최근에는 Q-Learning과 딥러닝을 결합한 DQN(Deep-Q-Network) 기법을 많이 활용합니다.

- 강화학습은 게임 환경이나 로봇 환경에 제한적으로 사용되고 있는 상황

### 트레이닝 데이터(Training Data), 테스트 데이터(Test Data)

- 머신러닝 모델은 일반적으로 지도학습 방법론을 사용합니다.
- 지도학습 방법론을 사용하기 위해서는 트레이닝 데이터의 구성이 (인풋 데이터, 데이터에 대한 정답) 쌍으로 구성되어 있어야만 합니다. 즉, 지도학습은 정답을 보여주면서 학습시키는 머신러닝 방법론입니다.
- 이때 보통 인풋 데이터를 x, 데이터에 대한 정답을 y라고 부릅니다.
- 즉, 데이터는 (x,y) 쌍으로 구성됩니다.

![sl](https://github.com/zacinthepark/TIL/assets/86648892/4e5baa3c-21f3-4772-8558-d7466c30334d)

- 예를 들어, 우리가 키를 기반으로 몸무게를 예측하는 모델을 만드는 경우를 생각해보면 트레이닝 데이터는 여러 사람에게서 수집한 키와 몸무게 데이터가 됩니다.

- 이런식으로 (x,y)로 구성된 데이터를 **학습용 데이터(Training Data)** 라고 부릅니다. 머신러닝 모델을 사용하는 경우 다음의 2가지 과정을 거칩니다.

1. 학습용 데이터로 머신러닝 모델을 학습시킵니다.
2. 학습되니 머신러닝 모델의 성능을 트레이닝 데이터에 포함되어 있지 않고 따로 빼놓은 **테스트 데이터(Test Data)** 로 측정합니다.

![training](https://github.com/zacinthepark/TIL/assets/86648892/777357f4-37c1-4a02-b11b-566598b86321)

- 테스트 데이터에 대해서는 실제 정답 데이터를 보여주지 않고, 예측값을 만든 뒤 예측값과 정답을 비교해서 학습된 머신러닝 모델의 성능을 검증

#### 트레이닝 데이터, 테스트 데이터 나누기(split)

- 따라서 머신러닝 모델을 학습시키기 위해서 전체 데이터의 일부를 Training Data, 일부는 Test Data로 나눠서 사용합니다.
- 일반적으로 데이터의 80% 정도는 트레이닝 데이터, 20% 정도는 테스트 데이터로 나눠서 사용합니다.
- 예를 들어 1000명의 (키, 몸무게) 데이터가 있다면 800명분의 데이터는 트레이닝 데이터, 200명분의 데이터는 테스트 데이터로 나눠서 사용합니다.
- scikit-learn에서 쉽게 split할 수 있는 함수를 제공

### 검증용 데이터(Validation Data), 오버피팅(Overfitting)

#### Validation Data

- 여기에 더 나아가서 전체 데이터를 트레이닝 데이터, 검증용 데이터, 테스트 데이터로 나누기도 합니다.
- 검증용 데이터는 트레이닝 과정에서 학습에 사용하지는 않지만 중간중간 테스트하는데 사용해서 학습하고 있는 모델이 오버피팅에 빠지지 않았는지 체크하는데 사용됩니다.
- 즉, 직관적으로 설명하면 검증용 데이터는 트레이닝 과정 중간에 사용하는 테스트 데이터로 볼 수 있습니다.

![data_split](https://github.com/zacinthepark/TIL/assets/86648892/4b130885-006f-4940-b13c-1b60fe788d18)

#### Overfitting(과적합), Underfitting

![overfitting](https://github.com/zacinthepark/TIL/assets/86648892/d48db1e8-7683-4142-8baf-481f228bb356)

- 학습 과정에서 트레이닝 에러와 검증 에러를 출력한 그래프
- 처음에는 트레이닝 에러와 검증 에러가 모두 작아지지만 일정 횟수 이상 반복할 경우 트레이닝 에러는 작아지지만 검증 에러는 커지는 **오버피팅(Overfitting)** 에 빠지게 됩니다.
- 따라서 트레이닝 에러는 작아지지만 검증 에러는 커지는 지점에서 업데이트를 중지하면 최적의 파라미터를 얻을 수 있습니다.

- 오버피팅(과적합)
    - 머신러닝 이론 중 하나
    - 학습 과정에서 트레이닝 데이터에만 최적화된 형태로 모델이 바뀌는 것
    - 트레이닝 데이터 형상에 맞게 과도하게 최적화되었다는 것
    - 자동차 분류 머신러닝 모델
        - 빨간색, 검은색, 하얀색 자동차들이 있을텐데 트레이닝 데이터셋에 우연히 빨간색 자동차가 만약 많이 모였다면, 이를 통해 트레이닝 시키면 해당 모델은 빨간색 자동차 인풋으로 들어오면 분류를 잘할텐데, 빨간색이 아닌 자동차가 들어오면 분류 성능이 급격히 떨어짐
    - 즉, 모델의 범용성이 나빠짐

- 이를 해결하기 위해서 Validation Data를 사용하여 트레이닝 중간중간에 트레이닝 데이터에 포함시켜놓지 않았던 검증 데이터를 통해 에러를 측정
    - train 70%, validation 15%, test 15%
- Validation Error가 커지는 시점이 발생하면 학습을 조기 종료한다고 하여 오버피팅을 방지하고, Early Stopping이라는 머신러닝 기법으로 부름

![overfitting_underfitting](https://github.com/zacinthepark/TIL/assets/86648892/cd0b6ec8-128d-4032-b68a-f16237c0a01c)

- **오버피팅(Overfitting)** 은 학습 과정에서 머신러닝 알고리즘의 파라미터가 트레이닝 데이터에 과도하게 최적화되어 트레이닝 데이터에 대해서는 잘 동작하지만 새로운 데이터인 테스트 데이터에 대해서는 잘동작하지 못하는 현상을 말합니다. 오버피팅은 모델의 표현력이 지나치게 강력할 경우 발생하기 쉽습니다.

- 그림은 오버피팅, 언더피팅의 경우를 보여줍니다. 가장 오른쪽 그림을 보면 모델이 트레이닝 데이터의 정확도를 높이기 위해 결정 직선(Decision Boundary)을 과도하게 꼬아서 그린 모습을 볼 수 있습니다. 이럴 경우 트레이닝 데이터와 조금 형태가 다른 새로운 데이터를 예측할 때도 성능이 떨어지게 됩니다.
- 이에 반해 가장 왼쪽 그림은 **언더피팅(Underfitting)** 에 빠진 상황을 보여줍니다. 언더피팅은 오버피팅의 반대 상황으로 모델의 표현력이 부족해서 트레이닝 데이터도 제대로 예측하지 못하는 상황을 말합니다.
    - 풀고자 하는 문제에 비해 사용하는 머신러닝 알고리즘이 간단할 때
    - 어느정도 결정 직선을 Non-linear하게 꼬아주는 과정이 필요
    - 완전 linear한 알고리즘을 사용하는 경우

- 중앙에 있는 그림은 오버피팅과 언더피팅에 빠지지 않고 파라미터가 적절히 학습된 경우를 보여줍니다.
- **문제 상황** 에 맞게 적절한 알고리즘을 선택하는 것이 중요한 요소

- 이런 오버피팅을 방지하기 위한 기법들을 **Regularization(정규화) 기법** 이라고 부릅니다.
