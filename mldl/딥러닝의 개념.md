모델링을 한다는 것은 오차를 줄이는 가중치, 파라미터를 찾는 과정이다
초기 파라미터 설정은 랜덤하다
loss function을 통해 오차를 계산
optimizer는 오차를 줄여주기 위해 어떤 방향으로 가중치를 조정해야할지 찾아주는 역할
learning_rate(학습률)은 오차를 얼마만큼 줄일지 결정하는 하이퍼파라미터, 가중치를 조정할 때 어느정도의 보폭으로 조정할지 결정
forward propagation(순전파): 모델로부터 오차를 계산하는 흐름 (오차를 전파한다)
backward propagation(역전파): 오차로부터 역으로 미분을 통해 파라미터를 조정하는 흐름 (오차를 역으로 전파한다)

표준화는 이상치가 많을 때 사용한다

Dense는 input_shape 모양의 노드들을 연결하여 output 개수만큼 출력하는 Layer
param 개수는 bias(w0)를 포함한 개수
input_shape는 분석단위
compile은 기계어로 변환하는 것

binary_crossentropy

- log: 1. 곱셈을 덧셈으로 바꿔준다 2. x가 0에 가까울수록 -inf, 1일 때 0, 그리고 1 이상일 때 단조증가하는 성격을 가지고 있음
- `-log` 그래프
- 0~1의 확률값에 관한 예측값에 대하여 `-log` 그래프를 기반으로 하여 오차를 계산

다중분류

다중분류에서 output layer의 노드의 수는 클래스의 수
setosa, versicolor, virginica에 대한 각각 값이 있다면, 이 중에서 가장 큰 값이 결론
softmax를 통해 예측값을 확률값으로 변환
categorical_crossentropy는 로그우도라고도 한다
배열의 인덱스가 인코딩된 범주

sparse_categorical_crossentropy

- binary_crossentropy처럼 `-log` 함수를 통해 오차를 계산
- 대신 softmax를 통해 얻은 확률값을 x 값으로 사용
- 1에 가까운 값이라면, 즉, 해당 범주일 확률이 1에 가까우면, 오차는 낮을 것
